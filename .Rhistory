#It shows the structure of dataset
str(data)
Sex = c("female","male")
data$Sex<-factor(Sex)
#Loading data from csv file
data <- read.csv("heart_attack.csv", sep = ",", header = T)
#To remove null values
data <- na.omit(data)
data$Sex<-factor(Sex)
#It shows the structure of dataset
str(data)
table(data$Sex)
table(data$num)
#It shows the structure of dataset
str(data)
num = c("No disease","Disease")
Sex = c("female","male")
data$num<-factor(data$num)
data$Sex<-factor(Sex)
#Converting numeric value of num to factor
data$num<-factor(ifelse(data$num > 0,"Disease","noDisease"))
#Return total count of the factors in the num column
table(data$num)
#Converting numeric value of num to factor
data$num<-factor(ifelse(data$num > 0,"Disease","noDisease"))
data$Sex<-factor(data$Sex)
data$num<-factor(data$num)
#It shows the structure of dataset
str(data)
#To remove null values
data <- na.omit(data)
#It shows the structure of dataset
str(data)
#Loading data from csv file
data <- read.csv("heart_attack.csv", sep = ",", header = T)
#To remove null values
data <- na.omit(data)
#It shows the structure of dataset
str(data)
data$num<-factor(data$num)
data$Sex<-factor(data$Sex)
#It shows the structure of dataset
str(data)
pairs(data)
#Loading data from csv file
data <- read.csv("heart_attack.csv", sep = ",", header = T)
#To remove null values
data <- na.omit(data)
#It shows the structure of dataset
str(data)
#Check dimensions of the dataset
dim(data)
#Converting numeric value of num to factor
data$num<-factor(ifelse(data$num > 0,"Disease","noDisease"))
data$num
#Return total count of the factors in the num column
table(data$num)
#It shows the structure of dataset
str(data)
#Plotting barplot
barplot(table(data$num),
main="Plot of Disease availability")
#Converting numeric value of sex to factor
data$Sex<-factor(ifelse(data$Sex==0,"female","male"))
table(data$Sex)
table(Sex = data$Sex, disease = data$num )
#Plotting disease based on sex
mosaicplot(data$Sex ~ data$num,
main="Disease by Gender", shade=FALSE,color=TRUE,
xlab="Gender", ylab="Heart disease")
boxplot(data$Age ~ data$num,
main="Fate by Age",
ylab="Age",xlab="Heart disease")
#plot between age and maximum heart rate
ggplot(data,aes(x = Age,y = max.heart.rate )) +
geom_point() +
geom_smooth()
pairs(data)
#Splitting in test and train data
tsize <- floor(0.6 * nrow(data))
dt <- sample(x = nrow(data), size = tsize)
dt.train = data[dt,]
dt.test = data[-dt,]
#Splitting in test and train data
tsize <- floor(0.7 * nrow(data))
dt <- sample(x = nrow(data), size = tsize)
dt.train = data[dt,]
dt.test = data[-dt,]
dim(dt.train)
dim(dt.test)
dim(data)
dim(dt.train)
dim(dt.test)
library(pROC)
install.packages("pROC")
library(pROC)
set.seed(10)
logRegModel <- train(num ~ ., data=dt.train, method = 'glm', family = 'binomial')
logRegModel
logRegPrediction <- predict(logRegModel, dt.test)
logRegPrediction
dt.test = data[-dt,]
View(dt.test)
logRegPredictionprob <- predict(logRegModel, dt.test, type='prob')[2]
logRegPredictionprob
View(logRegPredictionprob)
logRegPredictionprob <- predict(logRegModel, dt.test, type='prob')[1]
logRegPredictionprob <- predict(logRegModel, dt.test, type='prob')[1]
View(logRegPredictionprob)
logRegPredictionprob <- predict(logRegModel, dt.test, type='prob')[2]
logRegPredictionprob <- predict(logRegModel, dt.test, type='prob')[1]
logRegPredictionprobDes <- predict(logRegModel, dt.test, type='prob')[1]
logRegPredictionprobNo <- predict(logRegModel, dt.test, type='prob')[2]
logRegConfMat <- confusionMatrix(logRegPrediction, dt.test[,"num"])
logRegConfMat
AUC = list()
Accuracy = list()
#ROC Curve
AUC$logReg <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((logRegPredictionprobNo))))$auc
AUC$logReg
Accuracy$logReg <- logRegConfMat$overall['Accuracy']
Accuracy$logReg
roc
library(randomForest)
#Random Forest
set.seed(10)
RFModel <- randomForest(num ~ .,
data=dt.train,
importance=TRUE,
ntree=2000)
RFModel
varImpPlot(RFModel)
RFPrediction <- predict(RFModel, dt.test)
RFPrediction
RFPredictionprob = predict(RFModel,dt.test,type="prob")[, 2]
RFPredictionprob
View(RFPredictionprob)
RFPredictionprob = predict(RFModel,dt.test,type="prob")[1]
RFPredictionprob
RFPredictionprob = predict(RFModel,dt.test,type="prob")[,1]
RFPredictionprob
RFPredictionprobDes = predict(RFModel,dt.test,type="prob")[,1]
RFPredictionprobNo = predict(RFModel,dt.test,type="prob")[, 2]
RFConfMat <- confusionMatrix(RFPrediction, dt.test[,"num"])
RFConfMat
AUC$RF <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((RFPredictionprobNo))))$auc
AUC$RF
Accuracy$RF <- RFConfMat$overall['Accuracy']
Accuracy$RF
# run model
boostModel <- train(num ~ .,data=dt.train, method='gbm',
trControl=objControl, tuneGrid = gbmGrid, verbose=F)
# run model
boostModel <- train(num ~ .,data=dt.train, method='gbm',
trControl=objControl, tuneGrid = gbmGrid, verbose=F)
objControl <- trainControl(method='cv', number=10,  repeats = 10)
gbmGrid <-  expand.grid(interaction.depth =  c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode =10)
# run model
boostModel <- train(num ~ .,data=dt.train, method='gbm',
trControl=objControl, tuneGrid = gbmGrid, verbose=F)
boostModel
gbmGrid
# See model output in Appendix to get an idea how it selects best model
trellis.par.set(caretTheme())
plot(boostModel)
# See model output in Appendix to get an idea how it selects best model
#trellis.par.set(caretTheme())
#plot(boostModel)
boostPrediction <- predict(boostModel, dt.test)
boostPrediction
boostPredictionprob <- predict(boostModel, dt.test, type='prob')[2]
boostPredictionprob
boostPredictionprobDes <- predict(boostModel, dt.test, type='prob')[1]
boostPredictionprobDes
boostPredictionprobNo <- predict(boostModel, dt.test, type='prob')[2]
boostPredictionprobNo
boostConfMat <- confusionMatrix(boostPrediction, dt.test[,"num"])
boostConfMat
#ROC Curve
AUC$boost <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((boostPredictionprobNo))))$auc
Accuracy$boost <- boostConfMat$overall['Accuracy']
AUC$boost
Accuracy$boost
#It shows the structure of dataset
str(data)
feature.names=names(heart.data)
feature.names=names(data)
feature.names
gbmModel <- train(num ~ ., data = dt.train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "ROC")
#GBM
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
## Estimate class probabilities
classProbs = TRUE,
## Evaluate performance using
## the following function
summaryFunction = twoClassSummary)
set.seed(10)
gbmModel <- train(num ~ ., data = dt.train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "ROC")
gbmModel
gbmPrediction <- predict(gbmModel, dt.test)
gbmPrediction <- predict(gbmModel, dt.test)
gbmPredictionprobDis <- predict(gbmModel, dt.test, type='prob')[1]
gbmPredictionprobNo <- predict(gbmModel, dt.test, type='prob')[2]
gbmConfMat <- confusionMatrix(gbmPrediction, dt.test[,"num"])
#ROC Curve
AUC$gbm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((gbmPredictionprobNo))))$auc
AUC$gbm
Accuracy$gbm <- gbmConfMat$overall['Accuracy']
Accuracy$gbm
#Support Vector Machine
svmModel <- train(num ~ ., data = dt.train,
method = "svmRadial",
trControl = fitControl,
preProcess = c("center", "scale"),
tuneLength = 8,
metric = "ROC")
svmPrediction <- predict(svmModel, dt.test)
svmPrediction <- predict(svmModel, dt.test)
svmPredictionprobDis <- predict(svmModel, dt.test, type='prob')[1]
svmPredictionprobNo <- predict(svmModel, dt.test, type='prob')[2]
svmConfMat <- confusionMatrix(svmPrediction, dt.test[,"num"])
#ROC Curve
AUC$svm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((svmPredictionprob))))$auc
Accuracy$svm <- svmConfMat$overall['Accuracy']
#ROC Curve
AUC$svm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((svmPredictionprob))))$auc
#ROC Curve
AUC$svm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((svmPredictionprobNo))))$auc
AUC$svm
Accuracy$svm <- svmConfMat$overall['Accuracy']
Accuracy$svm
row.names <- names(Accuracy)
col.names <- c("AUC", "Accuracy")
cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
summary(logRegModel)
summary(logRegModel)$coeff
boostImp =varImp(boostModel, scale = FALSE)
boostImp =varImp(boostModel, scale = FALSE)
boostModel
boostImp =varImp(logRegModel, scale = FALSE)
row = rownames(varImp(logRegModel, scale = FALSE)$importance)
row = convert.names(row)
convert.names
rownames(boostImp$importance)=row
plot(boostImp,main = 'Variable importance for heart failure prediction with boosted tree')
row = convert.names(row)
varImpPlot(RFModel)
varImpPlot(RFModel)
varImpPlot(logRegModel)
row.names <- names(Accuracy)
col.names <- c("AUC", "Accuracy")
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
col.names <- c("AUC", "Accuracy")
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
row.names <- names(Accuracy)
col.names <- c("AUC", "Accuracy")
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
pred <- knn(train = dt.train[1:13], test = dt.test[1:13], cl = dt.train$num, k = 1)
install.packages("class")
library (class)
pred <- knn(train = dt.train[1:13], test = dt.test[1:13], cl = dt.train$num, k = 1)
library(e1071)
pred <- knn(train = dt.train[1:13], test = dt.test[1:13], cl = dt.train$num, k = 1)
library("gmodels")
install.packages("gmodels")
library("gmodels")
pred <- knn(train = dt.train[1:13], test = dt.test[1:13], cl = dt.train$num, k = 1)
pred <-knn(train = dt.train[1:13], test = dt.test[1:13], cl = dt.train$num, k = 1)
knn(train = dt.train, test = dt.test, cl = dt.train$num, k = 1)
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
#Naive Bayes Classification Model
m <- naiveBayes(as.matrix(dt.train), dt.train$num)
m
p = predict(m, as.matrix(dt.test))
confusionMatrix(p, data.test)
confusionMatrix(p, dt.test$num)
#Naive Bayes Classification Model
naive <- naiveBayes(as.matrix(dt.train), dt.train$num)
p = predict(naive, as.matrix(dt.test))
confusionMatrix(p, dt.test$num)
confusionMatrix(naivePredict, dt.test$num)
naivePredict = predict(naive, as.matrix(dt.test))
naivePredict = predict(naive, as.matrix(dt.test))
confusionMatrix(naivePredict, dt.test$num)
naivepredictprobDis <- predict(naive, dt.test, type = 'prob')[1]
naivepredictprobDis <- predict(naive, dt.test, type = 'prob')[,1]
naivepredictprobDis <- predict(naive, as.matrix(dt.test), type = 'prob')[,1]
naivepredictprobDis <- predict(naive, as.matrix(dt.test), type = 'prob')[1]
#Naive Bayes Classification Model
naive <- naiveBayes(dt.train, dt.train$num)
naivePredict = predict(naive, dt.test)
confusionMatrix(naivePredict, dt.test$num)
as.matrix(
#Naive Bayes Classification Model
naive <- naiveBayes(as.matrix(dt.train), dt.train$num)
naivePredict = predict(naive, as.matrix(dt.test))
naivepredictprobDis <- predict(naive, as.matrix(dt.test), type = 'prob')[,1]
confusionMatrix(naivePredict, dt.test$num)
naivepredictprobDis <- predict(naive, as.matrix(dt.test), type = 'prob')[1,]
maiveConfusssion <- confusionMatrix(naivePredict, dt.test$num)
Accuracy$naive <- maiveConfusssion$overall['Accuracy']
Accuracy$naive
naiveConfusssion <- confusionMatrix(naivePredict, dt.test$num)
Accuracy$naive <- naiveConfusssion$overall['Accuracy']
AUC$svm <- roc(as.numeric(dt.test$num)
AUC$svm <- roc(as.numeric(dt.test$num))
naivepredictprobDis <- predict(naive, as.matrix(dt.test), type = 'prob')[1,]
perf = performance(naivePredict, "tpr", "fpr")
install.packages("ROCR")
library(ROCR)
perf = performance(naivePredict, "tpr", "fpr")
naivepredictprobDis <- predict(naivePredict, as.matrix(dt.test), type = 'prob')[1,]
perf = performance(naivePredict, as.matrix(dt.test), type = 'prob')[1,]
#Initializing Libraries
library(ggplot2)
library(ISLR)
library(caret)
library(pROC)
library(randomForest)
library (class)
library(e1071)
#Setting Working Directory
setwd("C:\\Users\\HP\\Desktop\\ExpertSystem\\HeartAttackProject")
#Loading data from csv file
data <- read.csv("heart_attack.csv", sep = ",", header = T)
#To remove null values
data <- na.omit(data)
#It shows the structure of dataset
str(data)
#It shows the structure of dataset
str(data)
#Check dimensions of the dataset
dim(data)
#Converting numeric value of num to factor
data$num<-factor(ifelse(data$num > 0,"Disease","noDisease"))
data$num
#Return total count of the factors in the num column
table(data$num)
#Plotting barplot
barplot(table(data$num),
main="Plot of Disease availability")
#Converting numeric value of sex to factor
data$Sex<-factor(ifelse(data$Sex==0,"female","male"))
table(data$Sex)
table(Sex = data$Sex, disease = data$num )
#Plotting disease based on sex
mosaicplot(data$Sex ~ data$num,
main="Disease by Gender", shade=FALSE,color=TRUE,
xlab="Gender", ylab="Heart disease")
boxplot(data$Age ~ data$num,
main="Fate by Age",
ylab="Age",xlab="Heart disease")
#plot between age and maximum heart rate
ggplot(data,aes(x = Age,y = max.heart.rate )) +
geom_point() +
geom_smooth()
#Plotting Relationship between Variables
pairs(data)
#Splitting in test and train data
tsize <- floor(0.7 * nrow(data))
dt <- sample(x = nrow(data), size = tsize)
dt.train = data[dt,]
dt.test = data[-dt,]
View(dt.test)
View(data)
dim(dt.train)
dim(dt.test)
dim(dt.train)
#To store the area under the ROC
AUC = list()
#To store Accuracy
Accuracy = list()
#Logistic Regression
set.seed(10)
#Model training
logRegModel <- train(num ~ ., data=dt.train, method = 'glm', family = 'binomial')
#Predicting values for test data
logRegPrediction <- predict(logRegModel, dt.test)
#Probability of Desease
logRegPredictionprobDes <- predict(logRegModel, dt.test, type='prob')[1]
#Probability of non desease
logRegPredictionprobNo <- predict(logRegModel, dt.test, type='prob')[2]
#Confusion Matrix
logRegConfMat <- confusionMatrix(logRegPrediction, dt.test[,"num"])
logRegConfMat
AUC$logReg <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((logRegPredictionprobNo))))$auc
Accuracy$logReg <- logRegConfMat$overall['Accuracy']
summary(logRegModel)$coeff
#Model training
RFModel <- randomForest(num ~ .,
data=dt.train,
importance=TRUE,
ntree=2000)
varImpPlot(RFModel)
#Predicting values for test data
RFPrediction <- predict(RFModel, dt.test)
#Probability of Desease
RFPredictionprobDes = predict(RFModel,dt.test,type="prob")[,1]
#Probability of non desease
RFPredictionprobNo = predict(RFModel,dt.test,type="prob")[, 2]
#Confusion Matrix
RFConfMat <- confusionMatrix(RFPrediction, dt.test[,"num"])
RFConfMat
AUC$RF <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((RFPredictionprobNo))))$auc
Accuracy$RF <- RFConfMat$overall['Accuracy']
#Boosted tree model
set.seed(10)
objControl <- trainControl(method='cv', number=10,  repeats = 10)
gbmGrid <-  expand.grid(interaction.depth =  c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode =10)
#Train Model
boostModel <- train(num ~ .,data=dt.train, method='gbm',
trControl=objControl, tuneGrid = gbmGrid, verbose=F)
#Predicting values for test data
boostPrediction <- predict(boostModel, dt.test)
#Probability of Desease
boostPredictionprobDes <- predict(boostModel, dt.test, type='prob')[1]
#Probability of Non Desease
boostPredictionprobNo <- predict(boostModel, dt.test, type='prob')[2]
#Confusion Matrix
boostConfMat <- confusionMatrix(boostPrediction, dt.test[,"num"])
boostConfMat
#ROC Curve
AUC$boost <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((boostPredictionprobNo))))$auc
Accuracy$boost <- boostConfMat$overall['Accuracy']
#GBM
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
## Estimate class probabilities
classProbs = TRUE,
## Evaluate performance using the following function
summaryFunction = twoClassSummary)
#Train Model
gbmModel <- train(num ~ ., data = dt.train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "ROC")
#Predicting values for test data
gbmPrediction <- predict(gbmModel, dt.test)
#Probability of Desease
gbmPredictionprobDis <- predict(gbmModel, dt.test, type='prob')[1]
#Probability of Desease
gbmPredictionprobDis <- predict(gbmModel, dt.test, type='prob')[1]
#Probability of Non Desease
gbmPredictionprobNo <- predict(gbmModel, dt.test, type='prob')[2]
#Confusion Matrix
gbmConfMat <- confusionMatrix(gbmPrediction, dt.test[,"num"])
gbmConfMat
#ROC Curve
AUC$gbm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((gbmPredictionprobNo))))$auc
Accuracy$gbm <- gbmConfMat$overall['Accuracy']
#Support Vector Machine
#Train Model
svmModel <- train(num ~ ., data = dt.train,
method = "svmRadial",
trControl = fitControl,
preProcess = c("center", "scale"),
tuneLength = 8,
metric = "ROC")
#PRedict values for test data
svmPrediction <- predict(svmModel, dt.test)
#Probability of Desease
svmPredictionprobDis <- predict(svmModel, dt.test, type='prob')[1]
#Probability of Non Desease
svmPredictionprobNo <- predict(svmModel, dt.test, type='prob')[2]
#Confussion Matrix
svmConfMat <- confusionMatrix(svmPrediction, dt.test[,"num"])
svmConfMat
#ROC Curve
AUC$svm <- roc(as.numeric(dt.test$num),as.numeric(as.matrix((svmPredictionprobNo))))$auc
Accuracy$svm <- svmConfMat$overall['Accuracy']
row.names <- names(Accuracy)
col.names <- c("AUC", "Accuracy")
#Showing the accuracy table
total <- cbind(as.data.frame(matrix(c(AUC,Accuracy),nrow = 5, ncol = 2,
dimnames = list(row.names, col.names))))
total
